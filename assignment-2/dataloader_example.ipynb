{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_from_jsonl\n",
    "train_data = read_from_jsonl(\"train.jsonl\")\n",
    "test_data = read_from_jsonl(\"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n",
      "3453\n"
     ]
    }
   ],
   "source": [
    "#train_data[0]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "#test_data = test_data[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "train_data_encoded = deepcopy(train_data)\n",
    "test_data_encoded = deepcopy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "curr_one_hot_encoding_mapping = {\n",
    "    1: [1, 0, 0, 0],\n",
    "    2: [0, 1, 0, 0],\n",
    "    3: [0, 0, 1, 0],\n",
    "    4: [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "prev_one_hot_encoding_mapping = {\n",
    "    # 0 for start of string sequence\n",
    "    0: [1, 0, 0, 0, 0],\n",
    "    1: [0, 1, 0, 0, 0],\n",
    "    2: [0, 0, 1, 0, 0],\n",
    "    3: [0, 0, 0, 1, 0],\n",
    "    4: [0, 0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "for i, data in enumerate(train_data):\n",
    "    for j, pos in enumerate(data[\"pos_tags\"]):\n",
    "        if j == 0:\n",
    "            prev = prev_one_hot_encoding_mapping[0]\n",
    "            curr = curr_one_hot_encoding_mapping[pos]\n",
    "        else:\n",
    "            prev = prev_one_hot_encoding_mapping[data[\"pos_tags\"][j-1]]\n",
    "            curr = curr_one_hot_encoding_mapping[pos]\n",
    "        \n",
    "        train_data_encoded[i][\"pos_tags\"][j] = np.array(prev + curr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'chunk_tags': [1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
       " 'pos_tags': [array([1, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 1, 0]),\n",
       "  array([0, 0, 0, 1, 0, 1, 0, 0, 0]),\n",
       "  array([0, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 0, 1]),\n",
       "  array([0, 0, 0, 0, 1, 0, 0, 1, 0]),\n",
       "  array([0, 0, 0, 1, 0, 1, 0, 0, 0]),\n",
       "  array([0, 1, 0, 0, 0, 0, 0, 0, 1])]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_encoded[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data_encoded:\n",
    "    chunk_tags = np.array(i[\"chunk_tags\"])\n",
    "    i[\"chunk_tags\"] = chunk_tags\n",
    "    pos_tags = np.array(i[\"pos_tags\"])\n",
    "    pos_tags.reshape(1, pos_tags.shape[0], pos_tags.shape[1])\n",
    "    i[\"pos_tags\"] = pos_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'chunk_tags': array([1, 1, 1, 0, 1, 1, 1, 0, 1]),\n",
       " 'pos_tags': array([[1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9)\n",
      "(9,)\n",
      "(2, 9)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(train_data_encoded[i][\"pos_tags\"].shape)\n",
    "    print(train_data_encoded[i][\"chunk_tags\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader implementing Above things is in utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import read_from_jsonl\n",
    "from utils import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "train_data = read_from_jsonl(\"train.jsonl\")\n",
    "test_data = read_from_jsonl(\"test.jsonl\")\n",
    "\n",
    "train_data_loader = DataLoader(train_data[:3000], batch_size=len(train_data[:3000]))\n",
    "test_data_loader = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 3000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_data_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd0e97d0c554ecd87cd7b64d6d591f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Avg Loss : 0.4497814476490021\n",
      "Epoch 2 : Avg Loss : 0.43987584114074707\n",
      "Epoch 4 : Avg Loss : 0.4397176206111908\n",
      "Epoch 6 : Avg Loss : 0.43966320157051086\n",
      "Epoch 8 : Avg Loss : 0.4396343231201172\n",
      "Epoch 10 : Avg Loss : 0.43962419033050537\n"
     ]
    }
   ],
   "source": [
    "from utils import RecurrentPerceptron\n",
    "\n",
    "a = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "a.train_from_dataloader(train_data_loader, lr=0.05, nepochs=10, debug=False, print_interval=2)\n",
    "#a.load_model('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(16), 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.check_conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7311b9bc04f745e5a386fdb48c201810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3453 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc, prec, rec, f1 = a.test_from_dataloader(test_data_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8434\n",
      "Precision: 0.8100\n",
      "Recall: 0.9925\n",
      "F1 Score: 0.8920\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, overwriting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# running this will overwrite the model file\n",
    "a.save_model(path='/Users/keshav/Study/CS772/natural-language-processing-main 2/assignment-2', name='model_3000_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.6279, -1.8724, -3.7012, -2.8595,  1.8169,  0.4002,  4.3571,  0.7107,\n",
       "          5.5893]),\n",
       " tensor(-0.9459))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final weights\n",
    "a.W, a.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(model, data, k=5, nepochs=10, batch_size=1):\n",
    "\n",
    "\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    fold_size = len(data) // k\n",
    "    folds = [data[i:i+fold_size] for i in range(0, len(data), fold_size)]\n",
    "\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(k):\n",
    "        validation_data = folds[i]\n",
    "        train_data = [d for j, fold in enumerate(folds) if j != i for d in fold]\n",
    "        #print(len(train_data))\n",
    "        #print(len())\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "        validation_loader = DataLoader(validation_data, batch_size=batch_size)\n",
    "\n",
    "        model[i].train_from_dataloader(train_loader, lr=0.05, nepochs=10, debug=False, print_interval=2)\n",
    "        print(model[i].check_conditions())\n",
    "\n",
    "        accuracy, prec, rec, f1 = model[i].test_from_dataloader(validation_loader, verbose=False)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "\n",
    "        print(f\"Fold {i+1}/{k} - Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Fold {i+1}/{k} - Validation Precision: {prec:.4f}\")\n",
    "        print(f\"Fold {i+1}/{k} - Validation Recall: {rec:.4f}\")\n",
    "        print(f\"Fold {i+1}/{k} - Validation F1: {f1:.4f}\")\n",
    "\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_precisions = np.mean(accuracies)\n",
    "    avg_recalls = np.mean(recalls)\n",
    "    avg_f1s = np.mean(f1s)\n",
    "\n",
    "    print(f\"\\nAverage Validation Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"\\nAverage Validation Precision: {avg_precisions:.4f}\")\n",
    "    print(f\"\\nAverage Validation Recall: {avg_recalls:.4f}\")\n",
    "    print(f\"\\nAverage Validation F1: {avg_f1s:.4f}\")\n",
    "\n",
    "    return avg_accuracy, avg_precisions, avg_recalls, avg_f1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5b5ce531d041a0bd907db9fe7c724b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Avg Loss : 0.49011749029159546\n",
      "Epoch 2 : Avg Loss : 0.4841000735759735\n",
      "Epoch 4 : Avg Loss : 0.4838743209838867\n",
      "Epoch 6 : Avg Loss : 0.48380523920059204\n",
      "Epoch 8 : Avg Loss : 0.483770489692688\n",
      "Epoch 10 : Avg Loss : 0.4837600290775299\n",
      "(tensor(16), 16)\n",
      "Fold 1/5 - Validation Accuracy: 0.8886\n",
      "Fold 1/5 - Validation Precision: 0.8633\n",
      "Fold 1/5 - Validation Recall: 0.9947\n",
      "Fold 1/5 - Validation F1: 0.9244\n",
      "2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2267969be4774e98a0ddbc3bc9919424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Avg Loss : 0.479560911655426\n",
      "Epoch 2 : Avg Loss : 0.47662532329559326\n",
      "Epoch 4 : Avg Loss : 0.476403146982193\n",
      "Epoch 6 : Avg Loss : 0.4763326644897461\n",
      "Epoch 8 : Avg Loss : 0.4762992858886719\n",
      "Epoch 10 : Avg Loss : 0.47628864645957947\n",
      "(tensor(16), 16)\n",
      "Fold 2/5 - Validation Accuracy: 0.8911\n",
      "Fold 2/5 - Validation Precision: 0.8685\n",
      "Fold 2/5 - Validation Recall: 0.9937\n",
      "Fold 2/5 - Validation F1: 0.9269\n",
      "2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be4d771f03e44dd996fa1a537003883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Avg Loss : 0.49594491720199585\n",
      "Epoch 2 : Avg Loss : 0.490273118019104\n",
      "Epoch 4 : Avg Loss : 0.49004364013671875\n",
      "Epoch 6 : Avg Loss : 0.4899751842021942\n",
      "Epoch 8 : Avg Loss : 0.4899440109729767\n",
      "Epoch 10 : Avg Loss : 0.489935040473938\n",
      "(tensor(16), 16)\n",
      "Fold 3/5 - Validation Accuracy: 0.8979\n",
      "Fold 3/5 - Validation Precision: 0.8774\n",
      "Fold 3/5 - Validation Recall: 0.9927\n",
      "Fold 3/5 - Validation F1: 0.9315\n",
      "2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad0c9b0d238482e9c6a06ba0adee74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Avg Loss : 0.5019621849060059\n",
      "Epoch 2 : Avg Loss : 0.4893997609615326\n",
      "Epoch 4 : Avg Loss : 0.4891539514064789\n",
      "Epoch 6 : Avg Loss : 0.4890761375427246\n",
      "Epoch 8 : Avg Loss : 0.4890381395816803\n",
      "Epoch 10 : Avg Loss : 0.48902612924575806\n",
      "(tensor(16), 16)\n",
      "Fold 4/5 - Validation Accuracy: 0.8965\n",
      "Fold 4/5 - Validation Precision: 0.8753\n",
      "Fold 4/5 - Validation Recall: 0.9931\n",
      "Fold 4/5 - Validation F1: 0.9305\n",
      "2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919e440cc3464699aca73cb5ac61d54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Avg Loss : 0.4947036802768707\n",
      "Epoch 2 : Avg Loss : 0.4854482114315033\n",
      "Epoch 4 : Avg Loss : 0.48522648215293884\n",
      "Epoch 6 : Avg Loss : 0.485160768032074\n",
      "Epoch 8 : Avg Loss : 0.4851287305355072\n",
      "Epoch 10 : Avg Loss : 0.4851182997226715\n",
      "(tensor(16), 16)\n",
      "Fold 5/5 - Validation Accuracy: 0.8968\n",
      "Fold 5/5 - Validation Precision: 0.8750\n",
      "Fold 5/5 - Validation Recall: 0.9924\n",
      "Fold 5/5 - Validation F1: 0.9300\n",
      "\n",
      "Average Validation Accuracy: 0.8942\n",
      "\n",
      "Average Validation Precision: 0.8942\n",
      "\n",
      "Average Validation Recall: 0.9933\n",
      "\n",
      "Average Validation F1: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8941654249100065,\n",
       " 0.8941654249100065,\n",
       " 0.9933083322404525,\n",
       " 0.9286485825865753)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_data = read_from_jsonl(\"train.jsonl\")\n",
    "train_data = train_data[:3000]\n",
    "\n",
    "# Initialize the model\n",
    "a1 = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "a2 = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "a3 = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "a4 = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "a5 = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "model = [a1,a2,a3,a4,a5]\n",
    "#a.train_from_dataloader(train_data_loader, lr=0.05, nepochs=10, debug=False, print_interval=2)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "k_fold_cross_validation(model, train_data, k=5, nepochs=10, batch_size=1)\n",
    "\n",
    "#print(f\"\\nOverall 5-Fold Cross-Validation Accuracy: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall 5-Fold Cross-Validation Accuracy: 0.8941\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nOverall 5-Fold Cross-Validation Accuracy: {avg_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
