{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import read_from_jsonl\n",
    "from utils import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "train_data = read_from_jsonl(\"train.jsonl\")\n",
    "test_data = read_from_jsonl(\"test.jsonl\")\n",
    "\n",
    "train_data_loader = DataLoader(train_data[:2000], batch_size=len(train_data[:2000]))\n",
    "test_data_loader = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RecurrentPerceptron\n",
    "\n",
    "a = RecurrentPerceptron(clip_grads=True, clip=1., verbose=False)\n",
    "# a.train_from_dataloader(train_data_loader, lr=0.05, nepochs=500, debug=False, print_interval=50)\n",
    "a.load_model('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 21.9425,  12.3735,  10.4288,  11.9462,  15.9650, -14.3887, -10.7598,\n",
       "         -14.0571, -10.5215]),\n",
       " tensor(-0.6757))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.W, a.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84120b152a74035a7121606a2723224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3453 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8423)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.test_from_dataloader(test_data_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=array([1, 1, 1, 0, 0, 0])\n",
      "op=tensor([1, 1, 1, 0, 0, 1])\n",
      "y=array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       1, 1, 1])\n",
      "op=tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1])\n",
      "y=array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 1])\n",
      "op=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1])\n",
      "y=array([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1])\n",
      "op=tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1])\n",
      "y=array([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1])\n",
      "op=tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1])\n",
      "y=array([1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "op=tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "y=array([1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1])\n",
      "op=tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1])\n",
      "y=array([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "op=tensor([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "y=array([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1])\n",
      "op=tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
      "y=array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 0, 1])\n",
      "op=tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1])\n",
      "y=array([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
      "op=tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])\n",
      "y=array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "op=tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\n",
      "y=array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1])\n",
      "op=tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n",
      "y=array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
      "op=tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "y=array([1, 0])\n",
      "op=tensor([1, 1])\n",
      "y=array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1])\n",
      "op=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n",
      "y=array([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "op=tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n",
      "y=array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1])\n",
      "op=tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n",
      "y=array([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1])\n",
      "op=tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1])\n",
      "y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1])\n",
      "op=tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1])\n",
      "y=array([1, 1, 1, 0, 0, 0])\n",
      "op=tensor([1, 1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# num_cor = 0\n",
    "# total = 0\n",
    "num = 0\n",
    "incor_instances = []\n",
    "ops = []\n",
    "for d in tqdm(test_data_loader, disable=True) :\n",
    "    if num>20 : break \n",
    "    for b in d:\n",
    "        x = b[\"pos_tags\"]\n",
    "        y = b[\"chunk_tags\"]\n",
    "        op = a.infer(x)\n",
    "        if not torch.equal(op, torch.tensor(y)) : \n",
    "            print(f'{y=}')\n",
    "            print(f'{op=}')\n",
    "            num += 1\n",
    "            incor_instances.append(b)\n",
    "            ops.append(op)\n",
    "        # num_cor += sum(torch.tensor(y)==op)\n",
    "        # total += len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incor_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tokens': ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06'],\n",
       "  'chunk_tags': array([1, 1, 1, 0, 0, 0]),\n",
       "  'pos_tags': array([[1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 1]])},\n",
       " tensor([1, 1, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incor_instances[0], ops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
      "[1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1]\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1])\n"
     ]
    }
   ],
   "source": [
    "ins = 1\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
      "[1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1])\n"
     ]
    }
   ],
   "source": [
    "ins = 2\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['China', 'controlled', 'most', 'of', 'the', 'match', 'and', 'saw', 'several', 'chances', 'missed', 'until', 'the', '78th', 'minute', 'when', 'Uzbek', 'striker', 'Igor', 'Shkvyrin', 'took', 'advantage', 'of', 'a', 'misdirected', 'defensive', 'header', 'to', 'lob', 'the', 'ball', 'over', 'the', 'advancing', 'Chinese', 'keeper', 'and', 'into', 'an', 'empty', 'net', '.']\n",
      "[1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1\n",
      " 1 1 0 0 1]\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 3\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oleg', 'Shatskiku', 'made', 'sure', 'of', 'the', 'win', 'in', 'injury', 'time', ',', 'hitting', 'an', 'unstoppable', 'left', 'foot', 'shot', 'from', 'just', 'outside', 'the', 'area', '.']\n",
      "[1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1]\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 4\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Despite', 'winning', 'the', 'Asian', 'Games', 'title', 'two', 'years', 'ago', ',', 'Uzbekistan', 'are', 'in', 'the', 'finals', 'as', 'outsiders', '.']\n",
      "[1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1]\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 5\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two', 'goals', 'from', 'defensive', 'errors', 'in', 'the', 'last', 'six', 'minutes', 'allowed', 'Japan', 'to', 'come', 'from', 'behind', 'and', 'collect', 'all', 'three', 'points', 'from', 'their', 'opening', 'meeting', 'against', 'Syria', '.']\n",
      "[1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1]\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 6\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Takuya', 'Takagi', 'scored', 'the', 'winner', 'in', 'the', '88th', 'minute', ',', 'rising', 'to', 'head', 'a', 'Hiroshige', 'Yanagimoto', 'cross', 'towards', 'the', 'Syrian', 'goal', 'which', 'goalkeeper', 'Salem', 'Bitar', 'appeared', 'to', 'have', 'covered', 'but', 'then', 'allowed', 'to', 'slip', 'into', 'the', 'net', '.']\n",
      "[1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1]\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 7\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'was', 'the', 'second', 'costly', 'blunder', 'by', 'Syria', 'in', 'four', 'minutes', '.']\n",
      "[1 1 1 0 0 0 1 1 1 1 0 1]\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 8\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Defender', 'Hassan', 'Abbas', 'rose', 'to', 'intercept', 'a', 'long', 'ball', 'into', 'the', 'area', 'in', 'the', '84th', 'minute', 'but', 'only', 'managed', 'to', 'divert', 'it', 'into', 'the', 'top', 'corner', 'of', 'Bitar', \"'s\", 'goal', '.']\n",
      "[1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1]\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 9\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan', 'coach', 'Shu', 'Kamo', 'said', ':', \"'\", \"'\", 'The', 'Syrian', 'own', 'goal', 'proved', 'lucky', 'for', 'us', '.']\n",
      "[1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1]\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 10\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Syrians', 'scored', 'early', 'and', 'then', 'played', 'defensively', 'and', 'adopted', 'long', 'balls', 'which', 'made', 'it', 'hard', 'for', 'us', '.', \"'\"]\n",
      "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 11\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan', ',', 'co-hosts', 'of', 'the', 'World', 'Cup', 'in', '2002', 'and', 'ranked', '20th', 'in', 'the', 'world', 'by', 'FIFA', ',', 'are', 'favourites', 'to', 'regain', 'their', 'title', 'here', '.']\n",
      "[1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1]\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 12\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'four', 'teams', 'are', 'level', 'with', 'one', 'point', 'each', 'from', 'one', 'game', '.']\n",
      "[1 0 0 1 1 1 1 0 1 1 1 0 1]\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 13\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ROME', '1996-12-06']\n",
      "[1 0]\n",
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 14\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['on', 'Friday', 'for', 'their', 'friendly', 'against', 'Scotland', 'at', 'Murrayfield', 'more', 'than', 'a', 'year', 'after', 'the', '30-year-old', 'wing', 'announced', 'he', 'was', 'retiring', 'following', 'differences', 'over', 'selection', '.']\n",
      "[1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 15\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cuttitta', ',', 'who', 'trainer', 'George', 'Coste', 'said', 'was', 'certain', 'to', 'play', 'on', 'Saturday', 'week', ',', 'was', 'named', 'in', 'a', '21-man', 'squad', 'lacking', 'only', 'two', 'of', 'the', 'team', 'beaten', '54-21', 'by', 'England', 'at', 'Twickenham', 'last', 'month', '.']\n",
      "[1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1]\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 16\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stefano', 'Bordon', 'is', 'out', 'through', 'illness', 'and', 'Coste', 'said', 'he', 'had', 'dropped', 'back', 'row', 'Corrado', 'Covi', ',', 'who', 'had', 'been', 'recalled', 'for', 'the', 'England', 'game', 'after', 'five', 'years', 'out', 'of', 'the', 'national', 'team', '.']\n",
      "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1]\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 17\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cuttitta', 'announced', 'his', 'retirement', 'after', 'the', '1995', 'World', 'Cup', ',', 'where', 'he', 'took', 'issue', 'with', 'being', 'dropped', 'from', 'the', 'Italy', 'side', 'that', 'faced', 'England', 'in', 'the', 'pool', 'stages', '.']\n",
      "[1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 18\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coste', 'said', 'he', 'had', 'approached', 'the', 'player', 'two', 'months', 'ago', 'about', 'a', 'comeback', '.']\n",
      "[1 1 1 1 1 1 0 1 0 1 1 0 0 1]\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 19\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
      "[1 1 1 0 0 0]\n",
      "tensor([1, 1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ins = 20\n",
    "print(incor_instances[ins]['tokens'])\n",
    "print(incor_instances[ins]['chunk_tags'])\n",
    "print(ops[ins])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b6e2780ba3bd1772be0df4025a403065e66e23b1ff7d9620ea03694010dba6e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
